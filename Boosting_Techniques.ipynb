{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:  What is Boosting in Machine Learning? Explain how it improves weak learners.\n",
        "\n",
        "Answer: Boosting in Machine Learning\n",
        "\n",
        "Boosting is an ensemble learning technique in machine learning that aims to convert a collection of weak learners (models that perform only slightly better than random guessing) into a strong learner with high predictive accuracy. It does so by training models sequentially, where each new model focuses on correcting the errors made by the previous ones.\n",
        "\n",
        "What is a Weak Learner?\n",
        "\n",
        "A weak learner is a model that:\n",
        "\n",
        "Has low predictive power on its own\n",
        "\n",
        "Performs marginally better than random chance\n",
        "\n",
        "Often has high bias (e.g., shallow decision trees or decision stumps)\n",
        "\n",
        "How Boosting Works (Step-by-Step)\n",
        "\n",
        "Initialize Equal Weights\n",
        "All training data points start with equal importance (weights).\n",
        "\n",
        "Train the First Weak Learner\n",
        "The first model is trained on the original dataset.\n",
        "\n",
        "Increase Focus on Errors\n",
        "Misclassified data points are assigned higher weights, making them more influential in the next training step.\n",
        "\n",
        "Train the Next Weak Learner\n",
        "The next model is trained on the reweighted data, forcing it to focus more on difficult observations.\n",
        "\n",
        "Repeat Sequentially\n",
        "Steps 3 and 4 are repeated for multiple iterations.\n",
        "\n",
        "Combine All Learners\n",
        "The final prediction is a weighted combination (e.g., weighted vote or weighted average) of all weak learners.\n",
        "\n",
        "How Boosting Improves Weak Learners\n",
        "\n",
        "| Aspect                | Explanation                                                               |\n",
        "| --------------------- | ------------------------------------------------------------------------- |\n",
        "| **Error Correction**  | Each new learner explicitly focuses on the mistakes of previous learners. |\n",
        "| **Bias Reduction**    | Sequential learning helps reduce systematic errors, lowering bias.        |\n",
        "| **Adaptive Learning** | The model adapts to hard-to-predict data points.                          |\n",
        "| **Strong Ensemble**   | Many weak models together form a highly accurate predictor.               |\n"
      ],
      "metadata": {
        "id": "XFHspEeanUFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?\n",
        "\n",
        "Answer:  \n",
        "Difference Between AdaBoost and Gradient Boosting (Training Perspective)\n",
        "\n",
        "Both AdaBoost and Gradient Boosting are boosting ensemble methods, but they differ fundamentally in how each new model is trained and what it tries to correct.\n",
        "\n",
        "| Aspect                 | AdaBoost                                      | Gradient Boosting                                  |\n",
        "| ---------------------- | --------------------------------------------- | -------------------------------------------------- |\n",
        "| **Training Objective** | Focuses on **misclassified samples**          | Focuses on **minimizing a loss function**          |\n",
        "| **Error Handling**     | Increases **weights of misclassified points** | Fits new models to **residual errors (gradients)** |\n",
        "| **Model Dependency**   | Each model depends on **sample weights**      | Each model depends on **previous predictions**     |\n",
        "| **Mathematical Basis** | Weighted voting scheme                        | Gradient descent in function space                 |\n",
        "\n",
        "\n",
        "How Models Are Trained (Step-by-Step)\n",
        "AdaBoost (Adaptive Boosting)\n",
        "\n",
        "All training samples start with equal weights.\n",
        "\n",
        "A weak learner is trained on the weighted dataset.\n",
        "\n",
        "Misclassified points receive higher weights.\n",
        "\n",
        "The next learner is trained to focus more on these hard samples.\n",
        "\n",
        "Each model is assigned a weight based on its accuracy.\n",
        "\n",
        "Final prediction is a weighted vote of all models.\n",
        "\n",
        "Key idea: Learners focus on ‚Äúhard examples‚Äù directly.\n",
        "\n",
        "Gradient Boosting\n",
        "\n",
        "Start with an initial prediction (e.g., mean of target values).\n",
        "\n",
        "Compute residuals (difference between actual and predicted values).\n",
        "\n",
        "Train a new learner to predict these residuals.\n",
        "\n",
        "Add the new learner‚Äôs predictions to the existing model.\n",
        "\n",
        "Repeat until the loss function is minimized.\n",
        "\n",
        " Key idea: Learners focus on reducing the overall loss via gradients.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "0hup4ROYnUCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: How does regularization help in XGBoost?\n",
        "\n",
        "Answer:\n",
        "\n",
        "How Regularization Helps in XGBoost\n",
        "\n",
        "XGBoost (Extreme Gradient Boosting) incorporates explicit regularization into the boosting framework to control model complexity, making it more robust and less prone to overfitting compared to traditional gradient boosting.\n",
        "\n",
        "Why Regularization Is Needed in Boosting\n",
        "\n",
        "Boosting models:\n",
        "\n",
        "Add trees sequentially\n",
        "\n",
        "Can fit training data extremely well\n",
        "\n",
        "Are prone to overfitting, especially with deep trees and many boosting rounds\n",
        "\n",
        "Regularization ensures the model generalizes well to unseen data.\n",
        "\n",
        "Types of Regularization in XGBoost\n",
        "1. Tree Complexity Regularization (Structural Regularization)\n",
        "\n",
        "XGBoost penalizes overly complex trees using the following terms:\n",
        "\n",
        "Œ≥ (gamma) ‚Äì Penalizes the number of leaf nodes\n",
        "\n",
        "Encourages simpler trees\n",
        "\n",
        "A split is made only if it reduces loss more than Œ≥\n",
        "\n",
        "L1 (Œ± ‚Äì alpha) ‚Äì Lasso regularization on leaf weights\n",
        "\n",
        "Promotes sparsity\n",
        "\n",
        "Can prune insignificant leaves\n",
        "\n",
        "L2 (Œª ‚Äì lambda) ‚Äì Ridge regularization on leaf weights\n",
        "\n",
        "Prevents extreme weight values\n",
        "\n",
        "Improves numerical stability\n",
        "\n",
        "Effect: Controls how complex each tree can become.\n",
        "\n",
        "2. Shrinkage (Learning Rate)\n",
        "\n",
        "Scales down each tree‚Äôs contribution to the final prediction\n",
        "\n",
        "Forces the model to learn slowly and steadily\n",
        "\n",
        "Effect: Reduces overfitting by avoiding aggressive updates.\n",
        "\n",
        "3. Subsampling Regularization\n",
        "\n",
        "Row subsampling (subsample)\n",
        "Trains each tree on a random subset of rows\n",
        "\n",
        "Column subsampling (colsample_bytree, colsample_bylevel)\n",
        "Uses random subsets of features\n",
        "\n",
        "Effect: Introduces randomness, reducing variance and correlation between trees.\n",
        "\n",
        "Mathematical Intuition (Simplified)\n",
        "\n",
        "XGBoost minimizes the following objective function:\n",
        "\n",
        "Objective\n",
        "=\n",
        "Loss\n",
        "+\n",
        "Regularization\n",
        "Objective=Loss+Regularization\n",
        "\n",
        "Where regularization is:\n",
        "\n",
        "Œ©\n",
        "(\n",
        "ùëì\n",
        ")\n",
        "=\n",
        "ùõæ\n",
        "ùëá\n",
        "+\n",
        "1\n",
        "2\n",
        "ùúÜ\n",
        "‚àë\n",
        "ùë§\n",
        "ùëó\n",
        "2\n",
        "+\n",
        "ùõº\n",
        "‚àë\n",
        "‚à£\n",
        "ùë§\n",
        "ùëó\n",
        "‚à£\n",
        "Œ©(f)=Œ≥T+\n",
        "2\n",
        "1\n",
        "\t‚Äã\n",
        "\n",
        "Œª‚àëw\n",
        "j\n",
        "2\n",
        "\t‚Äã\n",
        "\n",
        "+Œ±‚àë‚à£w\n",
        "j\n",
        "\t‚Äã\n",
        "\n",
        "‚à£\n",
        "\n",
        "ùëá\n",
        "T: number of leaves\n",
        "\n",
        "ùë§\n",
        "ùëó\n",
        "w\n",
        "j\n",
        "\t‚Äã\n",
        "\n",
        ": leaf weights\n",
        "\n",
        "Interpretation: A tree must significantly reduce loss to justify added complexity."
      ],
      "metadata": {
        "id": "hF3Md7CenT_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Why is CatBoost considered efficient for handling categorical data?\n",
        "\n",
        "Answer:  Why CatBoost Is Efficient for Handling Categorical Data\n",
        "\n",
        "CatBoost (Categorical Boosting) is designed specifically to handle categorical features efficiently and accurately, without extensive manual preprocessing. Its core innovations address common problems that arise when categorical variables are used in gradient boosting models.\n",
        "\n",
        "Key Reasons for CatBoost‚Äôs Efficiency with Categorical Data\n",
        "1. Native Handling of Categorical Features\n",
        "\n",
        "Unlike most boosting algorithms that require one-hot encoding, CatBoost:\n",
        "\n",
        "Accepts categorical features directly\n",
        "\n",
        "Internally transforms categories into meaningful numerical representations\n",
        "\n",
        " Impact: Avoids high-dimensional sparse feature spaces and loss of information.\n",
        "\n",
        "2. Ordered Target Encoding (Avoids Target Leakage)\n",
        "\n",
        "Traditional target encoding can introduce data leakage. CatBoost solves this using ordered boosting:\n",
        "\n",
        "Computes category statistics using only previous data points\n",
        "\n",
        "Ensures no future information leaks into training\n",
        "\n",
        " Impact: Produces unbiased encodings and better generalization.\n",
        "\n",
        "3. Efficient Handling of High-Cardinality Categories\n",
        "\n",
        "CatBoost performs well when:\n",
        "\n",
        "Categorical variables have many unique values (e.g., user IDs, product IDs)\n",
        "\n",
        "It:\n",
        "\n",
        "Applies statistical encoding instead of expanding categories\n",
        "\n",
        "Uses combinations of categorical features automatically\n",
        "\n",
        " Impact: Maintains efficiency even with very large categorical spaces.\n",
        "\n",
        "4. Reduced Need for Feature Engineering\n",
        "\n",
        "With CatBoost:\n",
        "\n",
        "No manual encoding (Label / One-Hot / Mean Encoding) required\n",
        "\n",
        "Handles missing values and rare categories internally\n",
        "\n",
        " Impact: Faster experimentation and lower risk of preprocessing errors.\n",
        "\n",
        "5. Built-in Regularization for Categorical Splits\n",
        "\n",
        "CatBoost includes regularization strategies specifically for categorical features:\n",
        "\n",
        "Prevents overfitting on rare categories\n",
        "\n",
        "Stabilizes category statistics during training"
      ],
      "metadata": {
        "id": "qM0pAdk3nT9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some real-world applications where boosting techniques are preferred over bagging methods?\n",
        "\n",
        "\n",
        "Answer:  Real-World Applications Where Boosting Is Preferred Over Bagging\n",
        "\n",
        "Boosting techniques are preferred over bagging methods in scenarios where the primary challenge is high bias, complex decision boundaries, or the need for high predictive accuracy through sequential error correction. Below are prominent real-world applications where boosting consistently outperforms bagging.\n",
        "\n",
        "\n",
        "1. Credit Risk & Financial Fraud Detection\n",
        "\n",
        "Data is highly imbalanced\n",
        "\n",
        "Misclassification costs are asymmetric (false negatives are expensive)\n",
        "\n",
        "Boosting focuses on hard-to-classify fraudulent cases\n",
        "\n",
        "Why boosting?\n",
        "\n",
        "Sequential learning emphasizes rare but critical patterns that bagging often overlooks.\n",
        "\n",
        "2. Online Advertising & Marketing Analytics\n",
        "\n",
        "Predicting CTR, conversion probability, and churn\n",
        "\n",
        "High-dimensional features with non-linear interactions\n",
        "\n",
        " Why boosting?\n",
        "\n",
        "Boosting captures subtle interactions and reduces bias, improving business KPIs.\n",
        "\n",
        "Boosting vs Bagging: When Boosting Wins\n",
        "\n",
        "| Scenario         | Boosting         | Bagging    |\n",
        "| ---------------- | ---------------- | ---------- |\n",
        "| High Bias Models |  Excellent      |  Limited  |\n",
        "| Complex Patterns |  Strong         |  Moderate |\n",
        "| Imbalanced Data  |  Very Effective |  Weak     |\n",
        "| Interpretability |  Moderate       |  Higher   |\n"
      ],
      "metadata": {
        "id": "W8gDCNcNnTx3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMW7QghPm9iv",
        "outputId": "c7a91450-8bb2-4306-e8ae-cbdec285c5a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Classifier Accuracy: 0.9737\n"
          ]
        }
      ],
      "source": [
        "#Question 6: Write a Python program to: ‚óè Train an AdaBoost Classifier on the Breast Cancer dataset ‚óè Print the model accuracy\n",
        "\n",
        "# Import required libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize the AdaBoost Classifier\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "ada_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ada_clf.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"AdaBoost Classifier Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7:  Write a Python program to: ‚óè Train a Gradient Boosting Regressor on the California Housing dataset ‚óè Evaluate performance using R-squared score\n",
        "\n",
        "# Import required libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize the Gradient Boosting Regressor\n",
        "gbr = GradientBoostingRegressor(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "gbr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = gbr.predict(X_test)\n",
        "\n",
        "# Evaluate the model using R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Gradient Boosting Regressor R-squared Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YFcAVfAqPWx",
        "outputId": "ed155fae-6820-4e25-c891-799b224bfcc9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor R-squared Score: 0.8004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: Write a Python program to: ‚óè Train an XGBoost Classifier on the Breast Cancer dataset ‚óè Tune the learning rate using GridSearchCV ‚óè Print the best parameters and accuracy\n",
        "\n",
        "# Import required libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Initialize XGBoost Classifier\n",
        "xgb_clf = XGBClassifier(\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"logloss\",\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Parameter grid for tuning learning rate\n",
        "param_grid = {\n",
        "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
        "    \"n_estimators\": [100, 200]\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_clf,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD90WAWYqeBx",
        "outputId": "80a0d1e3-5808-4540-d010-1ff393916bee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [05:53:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.05, 'n_estimators': 200}\n",
            "Test Accuracy: 0.9474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Write a Python program to: ‚óè Train a CatBoost Classifier ‚óè Plot the confusion matrix using seaborn\n",
        "\n",
        "# Import required libraries\n",
        "!pip install catboost\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from catboost import CatBoostClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Initialize CatBoost Classifier\n",
        "cat_clf = CatBoostClassifier(\n",
        "    iterations=200,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "cat_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = cat_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"CatBoost Classifier Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot Confusion Matrix using seaborn\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=data.target_names,\n",
        "    yticklabels=data.target_names\n",
        ")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix - CatBoost Classifier\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "xtf6gzb8qtvM",
        "outputId": "4b7711ff-9d89-4bf5-d4c7-815fe9d3ae00"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.3.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n",
            "CatBoost Classifier Accuracy: 0.9737\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: You're working for a FinTech company trying to predict loan default using customer demographics and transaction behavior. The dataset is imbalanced, contains missing values, and has both numeric and categorical features. Describe your step-by-step data science pipeline using boosting techniques: ‚óè Data preprocessing & handling missing/categorical values ‚óè Choice between AdaBoost, XGBoost, or CatBoost ‚óè Hyperparameter tuning strategy ‚óè Evaluation metrics you'd choose and why ‚óè How the business would benefit from your model\n",
        "\n",
        "\n",
        "Answer:   \n",
        "\n",
        "Loan Default Prediction Using Boosting ‚Äì End-to-End Pipeline\n",
        "Problem Context\n",
        "\n",
        "Objective: Predict whether a customer will default on a loan\n",
        "\n",
        "Challenges:\n",
        "\n",
        "Class imbalance (defaults are rare)\n",
        "\n",
        "Missing values\n",
        "\n",
        "Numeric + categorical features\n",
        "\n",
        "Business Risk:\n",
        "\n",
        "False negatives ‚Üí Financial loss\n",
        "\n",
        "False positives ‚Üí Lost customers\n",
        "\n",
        "Step 1: Data Preprocessing\n",
        "\n",
        "1.1 Handling Missing Values\n",
        "\n",
        "| Feature Type | Strategy               | Reason                       |\n",
        "| ------------ | ---------------------- | ---------------------------- |\n",
        "| Numerical    | Median imputation      | Robust to outliers           |\n",
        "| Categorical  | Mode / native handling | Maintains category integrity |\n",
        "\n",
        "\n",
        "Why boosting helps\n",
        "\n",
        "Tree-based boosting models are less sensitive to scaling and tolerate imperfect imputations better than linear models.\n",
        "\n",
        "1.2 Handling Categorical Variables\n",
        "\n",
        "| Model                 | Handling Strategy               |\n",
        "| --------------------- | ------------------------------- |\n",
        "| AdaBoost              | Requires manual encoding        |\n",
        "| XGBoost               | One-hot / target encoding       |\n",
        "| **CatBoost (Chosen)** | **Native categorical handling** |\n",
        "\n",
        "\n",
        "Decision: CatBoost\n",
        "\n",
        "Avoids manual encoding\n",
        "\n",
        "Prevents target leakage using ordered boosting\n",
        "\n",
        "Handles missing + categorical features natively\n",
        "\n",
        "Step 2: Model Choice (Why CatBoost Over AdaBoost/XGBoost)\n",
        "\n",
        "| Model        | Limitation                       |\n",
        "| ------------ | -------------------------------- |\n",
        "| AdaBoost     | Sensitive to noise & outliers    |\n",
        "| XGBoost      | Requires extensive preprocessing |\n",
        "| **CatBoost** | Designed for this exact scenario |\n",
        "\n",
        "\n",
        "Step 3: Handling Class Imbalance\n",
        "\n",
        "Loan default data is typically highly imbalanced.\n",
        "\n",
        "Strategy\n",
        "\n",
        "Use class weights\n",
        "\n",
        "Optimize metrics beyond accuracy\n",
        "\n",
        "Step 4: Hyperparameter Tuning Strategy\n",
        "\n",
        "Parameters to Tune\n",
        "\n",
        "| Parameter     | Purpose              |\n",
        "| ------------- | -------------------- |\n",
        "| iterations    | Model capacity       |\n",
        "| learning_rate | Controls overfitting |\n",
        "| depth         | Tree complexity      |\n",
        "| l2_leaf_reg   | Regularization       |\n",
        "\n",
        "\n",
        "Approach\n",
        "\n",
        "GridSearch (small grid)\n",
        "\n",
        "Cross-validation\n",
        "\n",
        "Optimize ROC-AUC, not accuracy\n",
        "\n",
        "Step 5: Evaluation Metrics\n",
        "\n",
        "| Metric           | Why Chosen                 |\n",
        "| ---------------- | -------------------------- |\n",
        "| ROC-AUC          | Overall ranking quality    |\n",
        "| Recall (Default) | Minimize missed defaulters |\n",
        "| Precision        | Control false alarms       |\n",
        "| Confusion Matrix | Business interpretability  |\n",
        "\n",
        "\n",
        "Step 6: Business Impact\n",
        "Direct Benefits\n",
        "\n",
        "| Area            | Impact                   |\n",
        "| --------------- | ------------------------ |\n",
        "| Risk Management | Fewer bad loans          |\n",
        "| Revenue         | Better credit decisions  |\n",
        "| Compliance      | Transparent risk scoring |\n",
        "| Operations      | Automated decisioning    |\n",
        "\n"
      ],
      "metadata": {
        "id": "lMBwJjLErgH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 7\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Import Libraries\n",
        "# -----------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score\n",
        ")\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Create Sample Loan Dataset\n",
        "# (Demo-scale, intentionally small)\n",
        "# -----------------------------\n",
        "df = pd.DataFrame({\n",
        "    \"age\": [25, 45, np.nan, 35],\n",
        "    \"income\": [50000, 80000, 40000, np.nan],\n",
        "    \"employment_type\": [\"Salaried\", \"Self-Employed\", \"Salaried\", np.nan],\n",
        "    \"loan_default\": [0, 1, 0, 1]\n",
        "})\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Split Features & Target\n",
        "# -----------------------------\n",
        "X = df.drop(\"loan_default\", axis=1)\n",
        "y = df[\"loan_default\"]\n",
        "\n",
        "# Identify categorical columns\n",
        "cat_features = X.select_dtypes(include=\"object\").columns.tolist()\n",
        "\n",
        "# Fix: Convert NaN values in categorical features to string 'Missing'\n",
        "for col in cat_features:\n",
        "    X[col] = X[col].fillna('Missing').astype(str)\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Train-Test Split\n",
        "# FIXED: test_size increased to\n",
        "# allow stratification with 2 classes\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Initialize CatBoost Model\n",
        "# -----------------------------\n",
        "model = CatBoostClassifier(\n",
        "    iterations=300,\n",
        "    learning_rate=0.05,\n",
        "    depth=6,\n",
        "    loss_function=\"Logloss\",\n",
        "    eval_metric=\"AUC\",\n",
        "    class_weights=[1, 5],  # handle imbalance\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Train the Model\n",
        "# -----------------------------\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cat_features=cat_features\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Predictions\n",
        "# -----------------------------\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 8. Evaluation\n",
        "# -----------------------------\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBJvt3UOrP4T",
        "outputId": "e86fdccf-54b9-43f8-9c63-0d8d98d5445f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.5\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1 0]\n",
            " [1 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}